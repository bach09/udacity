{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "## Gather\n",
    "\n",
    "- Neste ponto foram feitos esforços para adquirir os dados necessários para o projeto. Primeiramente, foi gerado um arquivo no formato `TOML` que contém os tokens usados na API do Twitter, este arquivo é aberto como um dicionário pelo python utilizando a extensão toml. As variáveis constantes (em maiúsculo) são criadas com os valores desse token facilitando a manutenção do código e o objeto da API é criado. São utilizados `wait_on_rate_limit` e `wait_on_rate_limit_notify` para que, quando o tempo limite for excedido, a api espere para contínuar e avise dessa pausa;\n",
    "- Utilizando a url fornecida para o projeto 2, o arquivo `image-predictions.tsv` é carregado como um DataFrame diretamente, aproveitando os recursos das últimas versões do pandas que tem a capacidade de fazer download diretamente ao abrir o url;\n",
    "- O arquivo `twitter-archive-enhanced.csv` é carregado como o dataframe `twitter_archive`;\n",
    "- Utilizando os identificadores do dataframe `image_predicion` e a API do twitter, os tweets são baixados no formato json e gravados no arquivo `tweet_json.txt` linha por linha usando a forma de gravação `append` de arquivos do python. Também foi adicionado o comando mágico do ipython `%%time` para calcular o tempo de execução;\n",
    "- Utilizando o arquivo `tweet_json.txt` e acessar cada linha deste arquivo pegando as informações úteis e adicionando-as a um dataframe vazio chamado `df_tweets`.\n",
    "\n",
    "## Assess\n",
    "- Acessa informações úteis de cada dataframe para entender o conteúdo de seus dados, algumas das informações que são acessadas são: `sample(10)` para enxergar 10 amostras aleatórias; `info()` para verificar valores faltantes e os tipos de dados de cada coluna; `duplicated()` para verificar se valores estão duplicados. Ainda foram feitas outras visualizações que ajudaram a esclarecer o que poderia ser melhorado, como retweets existentes e replys de tweets originais;\n",
    "- Cada link de `extended_urls` foi acessado para descobrir se existiam tweets inexistentes e assim facilitar suas remoções;\n",
    "- Uma lista de tarefas para melhorar a qualidade e arrumação dos dataframes foi criada para servir como guia na limpeza.\n",
    "\n",
    "## Clean\n",
    "- Primeiramente, para cada item da lista foi criada uma definição, ou seja, uma informação do que foi realizado;\n",
    "- Essa ordem de limpeza foi definida por tabela, onde toda a limpeza de uma tabela era feita antes de prosseguir para a seguinte, a menos que a limpeza não fosse possível;\n",
    "- A baixo de cada definição, foi realizada a limpeza do código e um ou mais testes para verificar a corretitude da tabela depois da limpeza;\n",
    "- Ao terminar as limpezas de qualidade se seguiu para as limpezas de arrumação onde foi feita a junção das tabelas com as colunas necessárias e ideais;\n",
    "- O novo dataframe gerado pela junção ainda teve de receber alguns procedimentos de limpeza que serviram para melhorar a qualidade antes de ser salvo como `twitter_archive_master.csv`\n",
    "\n",
    "## Analyze\n",
    "- Algumas pequenas análises descritivas foram realizadas, com a geração de alguns gráficos, e foram escritos alguns insights dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import toml\n",
    "import time\n",
    "import tweepy\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load twitter tokens\n",
    "parse_tokens = toml.load('tokens.toml')\n",
    "\n",
    "# Set tweepy tokens\n",
    "CONSUMER_KEY = parse_tokens['tokens']['consumer_key']\n",
    "CONSUMER_SECRET = parse_tokens['tokens']['consumer_secret']\n",
    "ACCESS_TOKEN = parse_tokens['tokens']['access_token']\n",
    "ACCESS_SECRET = parse_tokens['tokens']['access_secret']\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image_predictions.tsv\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "r = requests.get(url)  \n",
    "with open('image_predictions.tsv', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "image_pretictions = pd.read_table('image_predictions.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tweets\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Take tweet json by tweet_id:\n",
    "# *AVISO*: Execução demorada\n",
    "id_404_erros = []\n",
    "# tweets = twitter_archive[(twitter_archive.retweeted_status_id.isnull()) & (twitter_archive.in_reply_to_status_id.isnull())]\n",
    "tweets = image_pretictions\n",
    "for tweet_id in tweets.tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        if tweet.user.id == 4196983835:\n",
    "            with open('tweet_json.txt', 'a') as outfile:\n",
    "                json.dump(tweet._json, outfile)\n",
    "                outfile.write('\\n')\n",
    "    except tweepy.TweepError:\n",
    "        #         if tweepy.TweepError.message[0]['code'] == 404:\n",
    "        id_404_erros.append(tweet_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera DataFrame de tweets puxados por id\n",
    "df_tweets = pd.DataFrame(columns=[\n",
    "                         'tweet_id', 'text', 'retweet_count', 'favorite_count', 'jpg_url', 'url', 'expanded_urls'])\n",
    "\n",
    "with open('tweet_json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            line_json = json.loads(line)\n",
    "            \n",
    "            if 'media' not in line_json['entities']:\n",
    "                continue\n",
    "            line_dict = {\n",
    "                'tweet_id': line_json['id_str'],\n",
    "                'text': line_json['full_text'],\n",
    "                'retweet_count': line_json['retweet_count'],\n",
    "                'favorite_count': line_json['favorite_count'],\n",
    "                'jpg_url': line_json['entities']['media'][0]['media_url_https'],\n",
    "                'url': line_json['entities']['media'][0]['url'],\n",
    "                'expanded_urls': line_json['entities']['media'][0]['expanded_url']\n",
    "            }\n",
    "\n",
    "            df_tweets = df_tweets.append(\n",
    "                pd.Series(line_dict).to_frame().transpose(), ignore_index=True) # Transpoem do formato de Serie para DataFrame\n",
    "\n",
    "        except Exception:\n",
    "            raise Exception(line)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show dataframe loaded head.\n",
    "image_pretictions.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions.loc[image_pretictions.jpg_url.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets e replys\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato do texto\n",
    "twitter_archive.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweet externo existente\n",
    "twitter_archive.loc[546, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reply\n",
    "twitter_archive.loc[twitter_archive.in_reply_to_status_id.notnull(), :]\n",
    "twitter_archive.loc[149, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de replys\n",
    "twitter_archive[twitter_archive.in_reply_to_status_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de retweets\n",
    "twitter_archive[twitter_archive.retweeted_status_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores que não foram verificados com machine learning\n",
    "temp = pd.merge(twitter_archive, image_pretictions,\n",
    "                on=['tweet_id'], how='outer')\n",
    "temp[temp.p1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando existencia de duplicados\n",
    "twitter_archive.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.rating_numerator == 1776].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Verificando links de tweets inexistentes\n",
    "# AVISO: Execução demorada.\n",
    "count = 0\n",
    "id_404 = []\n",
    "for index, row in twitter_archive[twitter_archive.expanded_urls.notna()].iterrows():\n",
    "    if requests.get(row.expanded_urls.split(',')[0]).status_code == 404:\n",
    "        print(row.expanded_urls.split(',')[0])\n",
    "        count += 1\n",
    "        id_404.append(row.tweet_id)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra linhas que url retorna erro 404\n",
    "twitter_archive[twitter_archive.tweet_id.isin(id_404)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores duplicados\n",
    "df_tweets.tweet_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "#### `image_pretictions` table\n",
    "- <del>Tipo de dados errado em `tweet_id`;</de>\n",
    "- <del>Textos com diferentes formas minusculos e maiusculos nas colunas `p1`, `p2` e `p3`;</del>\n",
    "- <del>Separação dos textos das colunas `p1`, `p2` e `p3` usando `_` ao invés de espaço.</del>\n",
    "\n",
    "#### `twitter_archive` table\n",
    "- <del>`in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` com valores incorres no formato `6.67152e+17`;</del>\n",
    "- <del>Tipo de dados errado em `tweet_id`, `in_reply_to_status_id`, `in_reply_to_user_id`, `timestamp`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`;</del>\n",
    "- <del>Valores nulos sendo representados como `nan` ao invés de `NaN` nas `colunas in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_id` e `retweeted_status_user_id`;</del>\n",
    "- <del>Valores nulos sendo representados como `None` em `doggo`, `floofer`, `pupper` e `puppo`;</del>\n",
    "- <del>Url repetidas na coluna `expanded_urls`;</del>\n",
    "- <del>Alguns links em expanded_urls levam a páginas com error 404;</de>\n",
    "- <del>Nem todos os ids tem predições.</del>\n",
    "- <del>Urls vazias;</del>\n",
    "- <del>Nomes de pets como `None` e `a`.</del>\n",
    "\n",
    "#### `df_tweets` table\n",
    "- <del>Valores nas colunas `retweet_count` e `favorite_count` estão como object ao invés de int.</del>\n",
    "\n",
    "#### `twitter_archive_master` table\n",
    "- <del>Limpar urls que não levam a dog_rates</del>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "- <del>Colunas `source` desnecessária em `twitter_archive`;</del>\n",
    "- <del>Retweets existentes, colunas `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`.</del>\n",
    "- <del>Replys existentes, colunas `in_reply_to_status_id`, `in_reply_to_user_id`;</del>\n",
    "- <del>`text` contém (texto, nota, url) em `twitter_archive` e `df_tweets`;</del>\n",
    "- <del>Quatro colunas em `twitter_archive` (`doggo`, `floofer`, `pupper` e `puppo`) ao invés de uma;</del>\n",
    "- <del>Denominador se mostra desnecessário sendo sempre 10 em `twitter_archive` na coluna `rating_denominator`;</del>\n",
    "- <del>Colunas `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`;</del>\n",
    "- <del>Numero de imagens na coluna `img_num` se mostra desnecessário em `image_predictions`.</del>\n",
    "- <del>Junção de `df_tweets`, `image_predicitions` e `twitter_archive`;</del>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean = image_pretictions.copy()\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "df_tweets_clean = df_tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `image_pretictions` table\n",
    "#### Define - Tipo de dados errado em `tweet_id`\n",
    "- Modifica o tipos dos valores da coluna `tweet_id` de inteiro para string usando `astype`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.tweet_id = image_pretictions_clean.tweet_id.astype(\n",
    "    'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- Textos com diferentes formas minusculos e maiusculos nas colunas p1, p2 e p3\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.p1 = image_pretictions_clean.p1.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))\n",
    "image_pretictions_clean.p2 = image_pretictions_clean.p2.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))\n",
    "image_pretictions_clean.p3 = image_pretictions_clean.p3.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.p1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean.p2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean.p3.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `twitter_archive` table\n",
    "\n",
    "#### Define - Valores nulos sendo representados como `None` em `doggo`, `floofer`, `pupper` e `puppo`\n",
    "- Modifica valores `None` para `np.nan` nas colunas `doggo`, `floofer`, `pupper` e `puppo`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.doggo = twitter_archive_clean.doggo.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.floofer = twitter_archive_clean.floofer.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.pupper = twitter_archive_clean.pupper.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.puppo = twitter_archive_clean.puppo.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.doggo.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.floofer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.pupper.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.puppo.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Tipo de dados errado em `tweet_id`, `in_reply_to_status_id`, `in_replay_to_user_id`, `timestamp`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`\n",
    "- Converte int para string nas colunas `tweet_id`, `in_reply_to_status_id`, `in_replay_to_user_id`, `retweeted_status_id` e `retweeted_status_user_id\n",
    "- Converte string para datetime nas colunas `timestamp` e  `retweeted_status_timestamp`\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conversão para string\n",
    "twitter_archive_clean.tweet_id = twitter_archive_clean.tweet_id.astype('str')\n",
    "twitter_archive_clean.in_reply_to_status_id = twitter_archive_clean.in_reply_to_status_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.in_reply_to_user_id = twitter_archive_clean.in_reply_to_user_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.retweeted_status_id = twitter_archive_clean.retweeted_status_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.retweeted_status_user_id = twitter_archive_clean.retweeted_status_user_id.astype(\n",
    "    'str')\n",
    "\n",
    "# Conversão para datatime\n",
    "twitter_archive_clean.timestamp = pd.to_datetime(\n",
    "    twitter_archive_clean.timestamp)\n",
    "twitter_archive_clean.retweeted_status_timestamp = pd.to_datetime(\n",
    "    twitter_archive_clean.retweeted_status_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.timestamp.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Url repetidas na coluna `expanded_urls`\n",
    "- Linhas onde a url se repete separados por `,` são dividas e apenas o primeiro valor permanece\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.expanded_urls = twitter_archive_clean.expanded_urls.apply(\n",
    "    lambda x: x if x is np.nan else x.split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.expanded_urls.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Alguns links em expanded_urls levam a páginas com error 404\n",
    "- Pela lista criada em `id_404` com identificadores que retornaram erro 404, seleciona as linhas e altera o valor para `np.nan`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(pd.Series(id_404).astype('str')), 'expanded_urls'] = \\\n",
    "    twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(\n",
    "        pd.Series(id_404).astype('str')), 'expanded_urls'].apply(lambda x: np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(\n",
    "    pd.Series(id_404).astype('str')), 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Nem todos os ids tem predições\n",
    "- Remove linhas desnecessárias que não possuem predição, selecionando os ids inexistentes na predição e removendo esses índices.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_predictions = twitter_archive_clean[~twitter_archive_clean.tweet_id.isin(\n",
    "    image_pretictions_clean.tweet_id)]\n",
    "twitter_archive_clean.drop(tweets_no_predictions.index, axis=0, inplace=True)\n",
    "# tweets_no_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[~twitter_archive_clean.tweet_id.isin(\n",
    "    image_pretictions_clean.tweet_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Valores nulos sendo representados como `nan` ao invés de `NaN` nas `colunas in_reply_to_user_id`, `in_reply_to_user_id`, `retweeted_status_id` e `retweeted_status_user_id`\n",
    "- Verifica as linhas em cada coluna e caso encontre `nan` troca por `np.nan`.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.in_reply_to_status_id = twitter_archive_clean.in_reply_to_status_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.in_reply_to_user_id = twitter_archive_clean.in_reply_to_user_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.retweeted_status_id = twitter_archive_clean.retweeted_status_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.retweeted_status_user_id = twitter_archive_clean.retweeted_status_user_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Urls vazias.\n",
    "- Seleciona as linhas onde a url se encontra como `np.nan` e remove essas linhas pelo id\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_list = twitter_archive_clean[(twitter_archive_clean.expanded_urls.isna())]\n",
    "twitter_archive_clean.drop(id_list.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[(twitter_archive_clean.expanded_urls.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Nomes de pets como `None` e `a`.\n",
    "- Seleciona nomes de pets que se encontram com valores `None` e `a` e os altera para `np.nan`\n",
    "\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.name = twitter_archive_clean.name.apply(\n",
    "    lambda x: np.nan if x == 'None' or x == 'a' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.query('name == \"None\" or name == \"a\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `df_tweets` table\n",
    "\n",
    "#### Define - Valores nas colunas retweet_count e favorite_count estão como float ao invés de int.\n",
    "- Seleciona as colunas `retweet_count` e `favorite_count` e usando astype converte para int.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets.retweet_count = df_tweets.retweet_count.astype('int')\n",
    "df_tweets.favorite_count = df_tweets.favorite_count.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "\n",
    "#### Define - Colunas `source` desnecessária em `twitter_archive`\n",
    "- Remove a coluna `source` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.drop(columns='source', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Retweets existentes, colunas `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`\n",
    "- Seleciona linhas que possuam identificação de reteweets e as remove utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se existe `retweeted_status_id` então existe `retweeted_status_user_id` e `retweeted_status_timestamp`\n",
    "twitter_archive_clean.drop(\n",
    "    twitter_archive_clean[twitter_archive_clean.retweeted_status_id.notna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.retweeted_status_id.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Replys existentes, colunas `in_reply_to_status_id`, `in_reply_to_user_id`.\n",
    "- Seleciona linhas que possuam identificação de replys e as remove utilizando `drop`\n",
    "\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se existe `in_reply_to_status_id` então existe `in_reply_to_user_id`\n",
    "twitter_archive_clean.drop(\n",
    "    twitter_archive_clean[twitter_archive_clean.in_reply_to_status_id.notna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.in_reply_to_status_id.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - `text` contém (texto, nota, url).\n",
    "- Limpa a coluna texto removendo a nota e a url utilizando expressão regular, mantendo apenas o texto do tweet\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.text = twitter_archive_clean.text.str.replace(r'(\\d+/\\d+)', '').str.replace(\n",
    "    r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '').str.strip()\n",
    "df_tweets_clean.text = df_tweets_clean.text.str.replace(r'(\\d+/\\d+)', '').str.replace(\n",
    "    r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '').str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.text.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.text.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Quatro colunas em `twitter_archive` (`doggo`, `floofer`, `pupper` e `puppo`) ao invés de uma.\n",
    "- Gera uma nova colunas `pet_class` e adiciona os valores `doggo`, `floofer`, `pupper` e `puppo`, ou a junção desses em caso de mais de uma classificação.\n",
    "- Remove as colunas `doggo`, `floofer`, `pupper` e `puppo` desnecessarias\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean['pet_class'] = twitter_archive_clean[[\n",
    "    'doggo', 'floofer', 'pupper', 'puppo']].fillna('').sum(axis=1)\n",
    "twitter_archive_clean.pet_class = twitter_archive_clean.pet_class.apply(\n",
    "    lambda x: np.nan if x is '' else x)\n",
    "twitter_archive_clean.drop(\n",
    "    columns=['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Denominador se mostra desnecessário sendo sempre 10 em `twitter_archive` na coluna `rating_denominator` - Colunas `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`.\n",
    "- Remove as colunas `rating_denominator`, `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.drop(columns=['rating_denominator', 'in_reply_to_status_id', 'in_reply_to_user_id',\n",
    "                                    'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Numero de imagens na coluna `img_num` se mostra desnecessário em `image_predictions`.\n",
    "- Remove a coluna `img_num` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.drop(columns='img_num', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Junção de df_tweets, image_predicitions e twitter_archive.\n",
    "- Gera um merge chamado `twitter_archive_master` com a junção das tabelas `twitter_archive` e `df_tweets`\n",
    "- Junta `twitter_archive_master` com a tabela faltante `image_predicions`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# junta `twitter_archive_clean` com `df_tweets_clean`\n",
    "twitter_archive_master = twitter_archive_clean.merge(\n",
    "    df_tweets_clean, how='left', on=['tweet_id', 'text', 'expanded_urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junta `twitter_archive_master` com `image_predictions_clean`\n",
    "twitter_archive_master = twitter_archive_master.merge(\n",
    "    image_pretictions_clean, how='left', on=['tweet_id', 'jpg_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `twitter_archive_master` table\n",
    "\n",
    "#### Define - Limpar urls que não levam a dog_rates\n",
    "- Seleciona urls que não contem `https://twitter.com/dog_rates` e remove as linhas utilizando os índices.\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_clean = twitter_archive_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove por tweets que não pertençam a https://twitter.com/dog_rates\n",
    "no_tweets_index = twitter_archive_master_clean[~twitter_archive_master_clean.expanded_urls.str.contains(\n",
    "    'https://twitter.com/dog_rates', regex=False)].index\n",
    "twitter_archive_master_clean.drop(no_tweets_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_master_clean[~twitter_archive_master_clean.expanded_urls.str.contains(\n",
    "    'https://twitter.com/dog_rates', regex=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_clean.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o dataframe\n",
    "df_tweets_archive = pd.read_csv(\n",
    "    'twitter_archive_master.csv', parse_dates=['timestamp'])\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.describe().to_csv('csv/tab1.csv')\n",
    "df_tweets_archive.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual a média das notas por classificação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.rating_numerator.describe().to_csv('csv/tab2.csv')\n",
    "df_tweets_archive.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive[df_tweets_archive.rating_numerator <=\n",
    "                  15].rating_numerator.describe().to_csv('csv/tab3.csv')\n",
    "df_tweets_archive[df_tweets_archive.rating_numerator <=\n",
    "                  15].rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=df_tweets_archive[df_tweets_archive.rating_numerator <= 15].rating_numerator)\n",
    "ax.set_title('Boxplot das notas atribuídas aos animais')\n",
    "ax.set_ylabel('Notas')\n",
    "ax.set_xticks([])\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig1.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Neste gráfico podemos verificar depois de remover as notas discrepantes, ou seja superiores a 15, assim removendo outliers (valores que podiam chegar a 1776, sendo que a nota deveria ser até 10 visto que o denominador é 10 mas os usuários como brincadeira classificam os animais com notas a cima desse valor), e com média de 10.49 e desvio de 2.19. Observa-se que existe uma homogeniedade da variância no boxplot, visto que a diferença entre o terceiro quartil e a mediana assim como a diferença entre o primeiro quartil e a mediana parecem ser a mesmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relação entre contagem de retweets e tweets favoritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax = sns.scatterplot(x=\"retweet_count\", y=\"favorite_count\",\n",
    "                     hue='pet_class', data=df_tweets_archive)\n",
    "ax.set_title('Contagens de retweets por tweets favoritados por classificação')\n",
    "ax.set_xlabel('Contagem retweets')\n",
    "ax.set_ylabel('Contagem tweets favoritos')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig2.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Esse é um gráfico de dispersão, entre a contagem de retweets e a contagem de tweets favoritos para cada classificação. Observa-se que a medida que aumenta a contagem de retweets aumenta a contagem de tweets favoritos (o que pode ser devido a maior visibilidade do tweet) e a classe que possui a maior evidência é a classe pupper. Vale salientar que é possível observar que a classe doggo possui observações com maiores números de retweets, consequentemente, maior contagem de tweets favoritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"pet_class\", y=\"retweet_count\", data=df_tweets_archive)\n",
    "labels = df_tweets_archive.pet_class.unique()[1:]\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=labels)\n",
    "ax.set_title('Contagens de retweets por classificação')\n",
    "ax.set_xlabel('Classificação dos animais')\n",
    "ax.set_ylabel('Contagem de retweets')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig3.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Por este gráfico é possível verificar que realmente a classificação doggo é a que possui o tweet com maior número de retweets, porém também podemos ver que pupper tem um grande concentração de retweets até 20000. Cachorros que possuem duas classificações são poucos com relação aos demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"pet_class\", y=\"favorite_count\", data=df_tweets_archive)\n",
    "labels = df_tweets_archive.pet_class.unique()[1:]\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=labels)\n",
    "ax.set_title('Contagens de tweets favoritados por classificação')\n",
    "ax.set_xlabel('Classificação dos animais')\n",
    "ax.set_ylabel('Contagem de tweets favoritos')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig4.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive[['retweet_count', 'favorite_count']].corr().to_csv('csv/tab4.csv')\n",
    "df_tweets_archive[['retweet_count', 'favorite_count']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Ao comparar a correlação entre `retweet_count` e `favorite_count` pode-se notar que existe uma forte correlação positiva entre as variáveis, isto é a médida que a contagem de retweets aumenta significa o quão favorito aquele tweet é com os usuários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contagem de tweets por data da post e classificação do animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = df_tweets_archive.set_index('timestamp')\n",
    "graph = graph.groupby([pd.Grouper(freq='M'), 'pet_class']).count()\n",
    "graph = graph.reset_index(level=['timestamp', 'pet_class'])\n",
    "\n",
    "ax = sns.lineplot(x='timestamp', y='tweet_id', data=graph, hue='pet_class')\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=graph.timestamp.dt.date)\n",
    "ax.set_title('Contagem de tweets por data e classificação')\n",
    "ax.set_xlabel('Data')\n",
    "ax.set_ylabel('Contagem')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig5.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Ao inicio é possível observar que a grande maioria dos tweets com classificação eram classificados unicamente como pupper, a medida que o tempo passa outras classificações são utilizadas e a contagem de tweets de cachorros denominados como pupper diminuiu. Observa-se que embora tenham ocorrido diferentes classificações, como doggo por exemplo, o número de tweets que possuem os animais denominados nessas classes diminuiu entre os anos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
