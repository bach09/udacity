{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "## Gather\n",
    "\n",
    "- Neste ponto foram feitos esforços para adquirir os dados necessários para o projeto. Primeiramente, foi gerado um arquivo no formato `TOML` que contém os tokens usados na API do Twitter, este arquivo é aberto como um dicionário pelo python utilizando a extensão toml. As variáveis constantes (em maiúsculo) são criadas com os valores desse token facilitando a manutenção do código e o objeto da API é criado. São utilizados `wait_on_rate_limit` e `wait_on_rate_limit_notify` para que, quando o tempo limite for excedido, a api espere para contínuar e avise dessa pausa;\n",
    "- Utilizando a url fornecida para o projeto 2, o arquivo `image-predictions.tsv` é carregado como um DataFrame diretamente, aproveitando os recursos das últimas versões do pandas que tem a capacidade de fazer download diretamente ao abrir o url;\n",
    "- O arquivo `twitter-archive-enhanced.csv` é carregado como o dataframe `twitter_archive`;\n",
    "- Utilizando os identificadores do dataframe `image_predicion` e a API do twitter, os tweets são baixados no formato json e gravados no arquivo `tweet_json.txt` linha por linha usando a forma de gravação `append` de arquivos do python. Também foi adicionado o comando mágico do ipython `%%time` para calcular o tempo de execução;\n",
    "- Utilizando o arquivo `tweet_json.txt` e acessar cada linha deste arquivo pegando as informações úteis e adicionando-as a um dataframe vazio chamado `df_tweets`.\n",
    "\n",
    "## Assess\n",
    "- Acessa informações úteis de cada dataframe para entender o conteúdo de seus dados, algumas das informações que são acessadas são: `sample(10)` para enxergar 10 amostras aleatórias; `info()` para verificar valores faltantes e os tipos de dados de cada coluna; `duplicated()` para verificar se valores estão duplicados. Ainda foram feitas outras visualizações que ajudaram a esclarecer o que poderia ser melhorado, como retweets existentes e replys de tweets originais;\n",
    "- Cada link de `extended_urls` foi acessado para descobrir se existiam tweets inexistentes e assim facilitar suas remoções;\n",
    "- Uma lista de tarefas para melhorar a qualidade e arrumação dos dataframes foi criada para servir como guia na limpeza.\n",
    "\n",
    "## Clean\n",
    "- Primeiramente, para cada item da lista foi criada uma definição, ou seja, uma informação do que foi realizado;\n",
    "- Essa ordem de limpeza foi definida por tabela, onde toda a limpeza de uma tabela era feita antes de prosseguir para a seguinte, a menos que a limpeza não fosse possível;\n",
    "- A baixo de cada definição, foi realizada a limpeza do código e um ou mais testes para verificar a corretitude da tabela depois da limpeza;\n",
    "- Ao terminar as limpezas de qualidade se seguiu para as limpezas de arrumação onde foi feita a junção das tabelas com as colunas necessárias e ideais;\n",
    "- O novo dataframe gerado pela junção ainda teve de receber alguns procedimentos de limpeza que serviram para melhorar a qualidade antes de ser salvo como `twitter_archive_master.csv`\n",
    "\n",
    "## Analyze\n",
    "- Algumas pequenas análises descritivas foram realizadas, com a geração de alguns gráficos, e foram escritos alguns insights dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import toml\n",
    "import time\n",
    "import tweepy\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load twitter tokens\n",
    "parse_tokens = toml.load('tokens.toml')\n",
    "\n",
    "# Set tweepy tokens\n",
    "CONSUMER_KEY = parse_tokens['tokens']['consumer_key']\n",
    "CONSUMER_SECRET = parse_tokens['tokens']['consumer_secret']\n",
    "ACCESS_TOKEN = parse_tokens['tokens']['access_token']\n",
    "ACCESS_SECRET = parse_tokens['tokens']['access_secret']\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image_predictions.tsv\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "r = requests.get(url)  \n",
    "with open('image_predictions.tsv', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "image_pretictions = pd.read_csv('image_predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tweets\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Take tweet json by tweet_id:\n",
    "# *AVISO*: Execução demorada\n",
    "id_404_erros = []\n",
    "# tweets = twitter_archive[(twitter_archive.retweeted_status_id.isnull()) & (twitter_archive.in_reply_to_status_id.isnull())]\n",
    "tweets = image_pretictions\n",
    "for tweet_id in tweets.tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        if tweet.user.id == 4196983835:\n",
    "            with open('tweet_json.txt', 'a') as outfile:\n",
    "                json.dump(tweet._json, outfile)\n",
    "                outfile.write('\\n')\n",
    "    except tweepy.TweepError:\n",
    "        #         if tweepy.TweepError.message[0]['code'] == 404:\n",
    "        id_404_erros.append(tweet_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>url</th>\n",
       "      <th>expanded_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>Here we have a Japanese Irish Setter. Lost eye...</td>\n",
       "      <td>504</td>\n",
       "      <td>2533</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>https://t.co/BLDqew2Ijj</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666020888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>This is a western brown Mitsubishi terrier. Up...</td>\n",
       "      <td>47</td>\n",
       "      <td>128</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>https://t.co/r7mOb2m0UI</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666029285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>Here is a very happy pup. Big fan of well-main...</td>\n",
       "      <td>43</td>\n",
       "      <td>124</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>https://t.co/y671yMhoiR</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666033412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>This is a purebred Piers Morgan. Loves to Netf...</td>\n",
       "      <td>139</td>\n",
       "      <td>294</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>https://t.co/DWnyCjf2mx</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666044226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>Here we have a 1949 1st generation vulpix. Enj...</td>\n",
       "      <td>41</td>\n",
       "      <td>107</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>https://t.co/4B7cOc1EDq</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666049248...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  666020888022790149  Here we have a Japanese Irish Setter. Lost eye...   \n",
       "1  666029285002620928  This is a western brown Mitsubishi terrier. Up...   \n",
       "2  666033412701032449  Here is a very happy pup. Big fan of well-main...   \n",
       "3  666044226329800704  This is a purebred Piers Morgan. Loves to Netf...   \n",
       "4  666049248165822465  Here we have a 1949 1st generation vulpix. Enj...   \n",
       "\n",
       "  retweet_count favorite_count  \\\n",
       "0           504           2533   \n",
       "1            47            128   \n",
       "2            43            124   \n",
       "3           139            294   \n",
       "4            41            107   \n",
       "\n",
       "                                           jpg_url                      url  \\\n",
       "0  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg  https://t.co/BLDqew2Ijj   \n",
       "1  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg  https://t.co/r7mOb2m0UI   \n",
       "2  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg  https://t.co/y671yMhoiR   \n",
       "3  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg  https://t.co/DWnyCjf2mx   \n",
       "4  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg  https://t.co/4B7cOc1EDq   \n",
       "\n",
       "                                       expanded_urls  \n",
       "0  https://twitter.com/dog_rates/status/666020888...  \n",
       "1  https://twitter.com/dog_rates/status/666029285...  \n",
       "2  https://twitter.com/dog_rates/status/666033412...  \n",
       "3  https://twitter.com/dog_rates/status/666044226...  \n",
       "4  https://twitter.com/dog_rates/status/666049248...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gera DataFrame de tweets puxados por id\n",
    "df_tweets = pd.DataFrame(columns=[\n",
    "                         'tweet_id', 'text', 'retweet_count', 'favorite_count', 'jpg_url', 'url', 'expanded_urls'])\n",
    "\n",
    "with open('tweet_json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            line_json = json.loads(line)\n",
    "            \n",
    "            if 'media' not in line_json['entities']:\n",
    "                continue\n",
    "            line_dict = {\n",
    "                'tweet_id': line_json['id_str'],\n",
    "                'text': line_json['full_text'],\n",
    "                'retweet_count': line_json['retweet_count'],\n",
    "                'favorite_count': line_json['favorite_count'],\n",
    "                'jpg_url': line_json['entities']['media'][0]['media_url_https'],\n",
    "                'url': line_json['entities']['media'][0]['url'],\n",
    "                'expanded_urls': line_json['entities']['media'][0]['expanded_url']\n",
    "            }\n",
    "\n",
    "            df_tweets = df_tweets.append(\n",
    "                pd.Series(line_dict).to_frame().transpose(), ignore_index=True) # Transpoem do formato de Serie para DataFrame\n",
    "\n",
    "        except Exception:\n",
    "            raise Exception(line)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>864197398364647424</td>\n",
       "      <td>https://pbs.twimg.com/media/C_4-8iPV0AA1Twg.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>True</td>\n",
       "      <td>Labrador_retriever</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>True</td>\n",
       "      <td>Tibetan_mastiff</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>701214700881756160</td>\n",
       "      <td>https://pbs.twimg.com/media/Cbs3DOAXIAAp3Bd.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.615163</td>\n",
       "      <td>True</td>\n",
       "      <td>Pembroke</td>\n",
       "      <td>0.159509</td>\n",
       "      <td>True</td>\n",
       "      <td>basenji</td>\n",
       "      <td>0.084466</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>676864501615042560</td>\n",
       "      <td>https://pbs.twimg.com/media/CWS0q8iU8AE2Srr.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Chesapeake_Bay_retriever</td>\n",
       "      <td>0.371146</td>\n",
       "      <td>True</td>\n",
       "      <td>water_buffalo</td>\n",
       "      <td>0.099596</td>\n",
       "      <td>False</td>\n",
       "      <td>Weimaraner</td>\n",
       "      <td>0.048968</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>680889648562991104</td>\n",
       "      <td>https://pbs.twimg.com/media/CXMBhXfWEAA4mMI.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.876337</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.078331</td>\n",
       "      <td>True</td>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>0.020407</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>666102155909144576</td>\n",
       "      <td>https://pbs.twimg.com/media/CT54YGiWUAEZnoK.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>English_setter</td>\n",
       "      <td>0.298617</td>\n",
       "      <td>True</td>\n",
       "      <td>Newfoundland</td>\n",
       "      <td>0.149842</td>\n",
       "      <td>True</td>\n",
       "      <td>borzoi</td>\n",
       "      <td>0.133649</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>684222868335505415</td>\n",
       "      <td>https://pbs.twimg.com/media/CX7Y_ByWwAEJdUy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>soft-coated_wheaten_terrier</td>\n",
       "      <td>0.791182</td>\n",
       "      <td>True</td>\n",
       "      <td>cocker_spaniel</td>\n",
       "      <td>0.072444</td>\n",
       "      <td>True</td>\n",
       "      <td>teddy</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>677301033169788928</td>\n",
       "      <td>https://pbs.twimg.com/media/CWZBsjPWsAAZFFl.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Japanese_spaniel</td>\n",
       "      <td>0.661178</td>\n",
       "      <td>True</td>\n",
       "      <td>Pekinese</td>\n",
       "      <td>0.150119</td>\n",
       "      <td>True</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.119720</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>669015743032369152</td>\n",
       "      <td>https://pbs.twimg.com/media/CUjSRNCXAAQ6Y_8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>comic_book</td>\n",
       "      <td>0.275927</td>\n",
       "      <td>False</td>\n",
       "      <td>bib</td>\n",
       "      <td>0.173516</td>\n",
       "      <td>False</td>\n",
       "      <td>jersey</td>\n",
       "      <td>0.073911</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>675710890956750848</td>\n",
       "      <td>https://pbs.twimg.com/media/CWCbd8ZWoAAtqoH.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>standard_schnauzer</td>\n",
       "      <td>0.441427</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_schnauzer</td>\n",
       "      <td>0.248885</td>\n",
       "      <td>True</td>\n",
       "      <td>Sealyham_terrier</td>\n",
       "      <td>0.164967</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>862457590147678208</td>\n",
       "      <td>https://pbs.twimg.com/media/C_gQmaTUMAAPYSS.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>home_theater</td>\n",
       "      <td>0.496348</td>\n",
       "      <td>False</td>\n",
       "      <td>studio_couch</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>False</td>\n",
       "      <td>barber_chair</td>\n",
       "      <td>0.052625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                          jpg_url  \\\n",
       "1954  864197398364647424  https://pbs.twimg.com/media/C_4-8iPV0AA1Twg.jpg   \n",
       "915   701214700881756160  https://pbs.twimg.com/media/Cbs3DOAXIAAp3Bd.jpg   \n",
       "532   676864501615042560  https://pbs.twimg.com/media/CWS0q8iU8AE2Srr.jpg   \n",
       "628   680889648562991104  https://pbs.twimg.com/media/CXMBhXfWEAA4mMI.jpg   \n",
       "16    666102155909144576  https://pbs.twimg.com/media/CT54YGiWUAEZnoK.jpg   \n",
       "692   684222868335505415  https://pbs.twimg.com/media/CX7Y_ByWwAEJdUy.jpg   \n",
       "544   677301033169788928  https://pbs.twimg.com/media/CWZBsjPWsAAZFFl.jpg   \n",
       "174   669015743032369152  https://pbs.twimg.com/media/CUjSRNCXAAQ6Y_8.jpg   \n",
       "494   675710890956750848  https://pbs.twimg.com/media/CWCbd8ZWoAAtqoH.jpg   \n",
       "1946  862457590147678208  https://pbs.twimg.com/media/C_gQmaTUMAAPYSS.jpg   \n",
       "\n",
       "      img_num                           p1   p1_conf  p1_dog  \\\n",
       "1954        4             golden_retriever  0.945905    True   \n",
       "915         1                    Chihuahua  0.615163    True   \n",
       "532         1     Chesapeake_Bay_retriever  0.371146    True   \n",
       "628         1            Shetland_sheepdog  0.876337    True   \n",
       "16          1               English_setter  0.298617    True   \n",
       "692         1  soft-coated_wheaten_terrier  0.791182    True   \n",
       "544         1             Japanese_spaniel  0.661178    True   \n",
       "174         1                   comic_book  0.275927   False   \n",
       "494         2           standard_schnauzer  0.441427    True   \n",
       "1946        1                 home_theater  0.496348   False   \n",
       "\n",
       "                       p2   p2_conf  p2_dog                p3   p3_conf  \\\n",
       "1954   Labrador_retriever  0.021264    True   Tibetan_mastiff  0.020493   \n",
       "915              Pembroke  0.159509    True           basenji  0.084466   \n",
       "532         water_buffalo  0.099596   False        Weimaraner  0.048968   \n",
       "628                collie  0.078331    True        Pomeranian  0.020407   \n",
       "16           Newfoundland  0.149842    True            borzoi  0.133649   \n",
       "692        cocker_spaniel  0.072444    True             teddy  0.071486   \n",
       "544              Pekinese  0.150119    True         Chihuahua  0.119720   \n",
       "174                   bib  0.173516   False            jersey  0.073911   \n",
       "494   miniature_schnauzer  0.248885    True  Sealyham_terrier  0.164967   \n",
       "1946         studio_couch  0.167256   False      barber_chair  0.052625   \n",
       "\n",
       "      p3_dog  \n",
       "1954    True  \n",
       "915     True  \n",
       "532     True  \n",
       "628     True  \n",
       "16      True  \n",
       "692    False  \n",
       "544     True  \n",
       "174    False  \n",
       "494     True  \n",
       "1946   False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show dataframe loaded head.\n",
    "image_pretictions.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      "tweet_id    2075 non-null int64\n",
      "jpg_url     2075 non-null object\n",
      "img_num     2075 non-null int64\n",
      "p1          2075 non-null object\n",
      "p1_conf     2075 non-null float64\n",
      "p1_dog      2075 non-null bool\n",
      "p2          2075 non-null object\n",
      "p2_conf     2075 non-null float64\n",
      "p2_dog      2075 non-null bool\n",
      "p3          2075 non-null object\n",
      "p3_conf     2075 non-null float64\n",
      "p3_dog      2075 non-null bool\n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "image_pretictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions.loc[image_pretictions.jpg_url.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets e replys\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato do texto\n",
    "twitter_archive.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweet externo existente\n",
    "twitter_archive.loc[546, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reply\n",
    "twitter_archive.loc[twitter_archive.in_reply_to_status_id.notnull(), :]\n",
    "twitter_archive.loc[149, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de replys\n",
    "twitter_archive[twitter_archive.in_reply_to_status_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de retweets\n",
    "twitter_archive[twitter_archive.retweeted_status_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores que não foram verificados com machine learning\n",
    "temp = pd.merge(twitter_archive, image_pretictions,\n",
    "                on=['tweet_id'], how='outer')\n",
    "temp[temp.p1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando existencia de duplicados\n",
    "twitter_archive.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.rating_numerator == 1776].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Verificando links de tweets inexistentes\n",
    "# AVISO: Execução demorada.\n",
    "count = 0\n",
    "id_404 = []\n",
    "for index, row in twitter_archive[twitter_archive.expanded_urls.notna()].iterrows():\n",
    "    if requests.get(row.expanded_urls.split(',')[0]).status_code == 404:\n",
    "        print(row.expanded_urls.split(',')[0])\n",
    "        count += 1\n",
    "        id_404.append(row.tweet_id)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra linhas que url retorna erro 404\n",
    "twitter_archive[twitter_archive.tweet_id.isin(id_404)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores duplicados\n",
    "df_tweets.tweet_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "#### `image_pretictions` table\n",
    "- <del>Tipo de dados errado em `tweet_id`;</de>\n",
    "- <del>Textos com diferentes formas minusculos e maiusculos nas colunas `p1`, `p2` e `p3`;</del>\n",
    "- <del>Separação dos textos das colunas `p1`, `p2` e `p3` usando `_` ao invés de espaço.</del>\n",
    "\n",
    "#### `twitter_archive` table\n",
    "- <del>`in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` com valores incorres no formato `6.67152e+17`;</del>\n",
    "- <del>Tipo de dados errado em `tweet_id`, `in_reply_to_status_id`, `in_reply_to_user_id`, `timestamp`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`;</del>\n",
    "- <del>Valores nulos sendo representados como `nan` ao invés de `NaN` nas `colunas in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_id` e `retweeted_status_user_id`;</del>\n",
    "- <del>Valores nulos sendo representados como `None` em `doggo`, `floofer`, `pupper` e `puppo`;</del>\n",
    "- <del>Url repetidas na coluna `expanded_urls`;</del>\n",
    "- <del>Alguns links em expanded_urls levam a páginas com error 404;</de>\n",
    "- <del>Nem todos os ids tem predições.</del>\n",
    "- <del>Urls vazias;</del>\n",
    "- <del>Nomes de pets como `None` e `a`.</del>\n",
    "\n",
    "#### `df_tweets` table\n",
    "- <del>Valores nas colunas `retweet_count` e `favorite_count` estão como object ao invés de int.</del>\n",
    "\n",
    "#### `twitter_archive_master` table\n",
    "- <del>Limpar urls que não levam a dog_rates</del>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "- <del>Colunas `source` desnecessária em `twitter_archive`;</del>\n",
    "- <del>Retweets existentes, colunas `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`.</del>\n",
    "- <del>Replys existentes, colunas `in_reply_to_status_id`, `in_reply_to_user_id`;</del>\n",
    "- <del>`text` contém (texto, nota, url) em `twitter_archive` e `df_tweets`;</del>\n",
    "- <del>Quatro colunas em `twitter_archive` (`doggo`, `floofer`, `pupper` e `puppo`) ao invés de uma;</del>\n",
    "- <del>Denominador se mostra desnecessário sendo sempre 10 em `twitter_archive` na coluna `rating_denominator`;</del>\n",
    "- <del>Colunas `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`;</del>\n",
    "- <del>Numero de imagens na coluna `img_num` se mostra desnecessário em `image_predictions`.</del>\n",
    "- <del>Junção de `df_tweets`, `image_predicitions` e `twitter_archive`;</del>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean = image_pretictions.copy()\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "df_tweets_clean = df_tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `image_pretictions` table\n",
    "#### Define - Tipo de dados errado em `tweet_id`\n",
    "- Modifica o tipos dos valores da coluna `tweet_id` de inteiro para string usando `astype`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.tweet_id = image_pretictions_clean.tweet_id.astype(\n",
    "    'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- Textos com diferentes formas minusculos e maiusculos nas colunas p1, p2 e p3\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.p1 = image_pretictions_clean.p1.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))\n",
    "image_pretictions_clean.p2 = image_pretictions_clean.p2.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))\n",
    "image_pretictions_clean.p3 = image_pretictions_clean.p3.apply(\n",
    "    lambda x: x.lower().replace('_', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.p1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean.p2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretictions_clean.p3.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `twitter_archive` table\n",
    "\n",
    "#### Define - Valores nulos sendo representados como `None` em `doggo`, `floofer`, `pupper` e `puppo`\n",
    "- Modifica valores `None` para `np.nan` nas colunas `doggo`, `floofer`, `pupper` e `puppo`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.doggo = twitter_archive_clean.doggo.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.floofer = twitter_archive_clean.floofer.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.pupper = twitter_archive_clean.pupper.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)\n",
    "twitter_archive_clean.puppo = twitter_archive_clean.puppo.apply(\n",
    "    lambda x: np.nan if x == 'None' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.doggo.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.floofer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.pupper.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.puppo.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Tipo de dados errado em `tweet_id`, `in_reply_to_status_id`, `in_replay_to_user_id`, `timestamp`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`\n",
    "- Converte int para string nas colunas `tweet_id`, `in_reply_to_status_id`, `in_replay_to_user_id`, `retweeted_status_id` e `retweeted_status_user_id\n",
    "- Converte string para datetime nas colunas `timestamp` e  `retweeted_status_timestamp`\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conversão para string\n",
    "twitter_archive_clean.tweet_id = twitter_archive_clean.tweet_id.astype('str')\n",
    "twitter_archive_clean.in_reply_to_status_id = twitter_archive_clean.in_reply_to_status_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.in_reply_to_user_id = twitter_archive_clean.in_reply_to_user_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.retweeted_status_id = twitter_archive_clean.retweeted_status_id.astype(\n",
    "    'str')\n",
    "twitter_archive_clean.retweeted_status_user_id = twitter_archive_clean.retweeted_status_user_id.astype(\n",
    "    'str')\n",
    "\n",
    "# Conversão para datatime\n",
    "twitter_archive_clean.timestamp = pd.to_datetime(\n",
    "    twitter_archive_clean.timestamp)\n",
    "twitter_archive_clean.retweeted_status_timestamp = pd.to_datetime(\n",
    "    twitter_archive_clean.retweeted_status_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.timestamp.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Url repetidas na coluna `expanded_urls`\n",
    "- Linhas onde a url se repete separados por `,` são dividas e apenas o primeiro valor permanece\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.expanded_urls = twitter_archive_clean.expanded_urls.apply(\n",
    "    lambda x: x if x is np.nan else x.split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.expanded_urls.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Alguns links em expanded_urls levam a páginas com error 404\n",
    "- Pela lista criada em `id_404` com identificadores que retornaram erro 404, seleciona as linhas e altera o valor para `np.nan`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(pd.Series(id_404).astype('str')), 'expanded_urls'] = \\\n",
    "    twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(\n",
    "        pd.Series(id_404).astype('str')), 'expanded_urls'].apply(lambda x: np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[twitter_archive_clean.tweet_id.isin(\n",
    "    pd.Series(id_404).astype('str')), 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Nem todos os ids tem predições\n",
    "- Remove linhas desnecessárias que não possuem predição, selecionando os ids inexistentes na predição e removendo esses índices.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_predictions = twitter_archive_clean[~twitter_archive_clean.tweet_id.isin(\n",
    "    image_pretictions_clean.tweet_id)]\n",
    "twitter_archive_clean.drop(tweets_no_predictions.index, axis=0, inplace=True)\n",
    "# tweets_no_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[~twitter_archive_clean.tweet_id.isin(\n",
    "    image_pretictions_clean.tweet_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Valores nulos sendo representados como `nan` ao invés de `NaN` nas `colunas in_reply_to_user_id`, `in_reply_to_user_id`, `retweeted_status_id` e `retweeted_status_user_id`\n",
    "- Verifica as linhas em cada coluna e caso encontre `nan` troca por `np.nan`.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.in_reply_to_status_id = twitter_archive_clean.in_reply_to_status_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.in_reply_to_user_id = twitter_archive_clean.in_reply_to_user_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.retweeted_status_id = twitter_archive_clean.retweeted_status_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)\n",
    "twitter_archive_clean.retweeted_status_user_id = twitter_archive_clean.retweeted_status_user_id.apply(\n",
    "    lambda x: x if x != 'nan' else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Urls vazias.\n",
    "- Seleciona as linhas onde a url se encontra como `np.nan` e remove essas linhas pelo id\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_list = twitter_archive_clean[(twitter_archive_clean.expanded_urls.isna())]\n",
    "twitter_archive_clean.drop(id_list.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[(twitter_archive_clean.expanded_urls.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Nomes de pets como `None` e `a`.\n",
    "- Seleciona nomes de pets que se encontram com valores `None` e `a` e os altera para `np.nan`\n",
    "\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.name = twitter_archive_clean.name.apply(\n",
    "    lambda x: np.nan if x == 'None' or x == 'a' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.query('name == \"None\" or name == \"a\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `df_tweets` table\n",
    "\n",
    "#### Define - Valores nas colunas retweet_count e favorite_count estão como float ao invés de int.\n",
    "- Seleciona as colunas `retweet_count` e `favorite_count` e usando astype converte para int.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets.retweet_count = df_tweets.retweet_count.astype('int')\n",
    "df_tweets.favorite_count = df_tweets.favorite_count.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "\n",
    "#### Define - Colunas `source` desnecessária em `twitter_archive`\n",
    "- Remove a coluna `source` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.drop(columns='source', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Retweets existentes, colunas `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`\n",
    "- Seleciona linhas que possuam identificação de reteweets e as remove utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se existe `retweeted_status_id` então existe `retweeted_status_user_id` e `retweeted_status_timestamp`\n",
    "twitter_archive_clean.drop(\n",
    "    twitter_archive_clean[twitter_archive_clean.retweeted_status_id.notna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.retweeted_status_id.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Replys existentes, colunas `in_reply_to_status_id`, `in_reply_to_user_id`.\n",
    "- Seleciona linhas que possuam identificação de replys e as remove utilizando `drop`\n",
    "\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se existe `in_reply_to_status_id` então existe `in_reply_to_user_id`\n",
    "twitter_archive_clean.drop(\n",
    "    twitter_archive_clean[twitter_archive_clean.in_reply_to_status_id.notna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.in_reply_to_status_id.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - `text` contém (texto, nota, url).\n",
    "- Limpa a coluna texto removendo a nota e a url utilizando expressão regular, mantendo apenas o texto do tweet\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.text = twitter_archive_clean.text.str.replace(r'(\\d+/\\d+)', '').str.replace(\n",
    "    r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '').str.strip()\n",
    "df_tweets_clean.text = df_tweets_clean.text.str.replace(r'(\\d+/\\d+)', '').str.replace(\n",
    "    r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '').str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.text.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.text.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Quatro colunas em `twitter_archive` (`doggo`, `floofer`, `pupper` e `puppo`) ao invés de uma.\n",
    "- Gera uma nova colunas `pet_class` e adiciona os valores `doggo`, `floofer`, `pupper` e `puppo`, ou a junção desses em caso de mais de uma classificação.\n",
    "- Remove as colunas `doggo`, `floofer`, `pupper` e `puppo` desnecessarias\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter_archive_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a7d4556cbf13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m twitter_archive_clean['pet_class'] = twitter_archive_clean[[\n\u001b[0m\u001b[1;32m      2\u001b[0m     'doggo', 'floofer', 'pupper', 'puppo']].fillna('').sum(axis=1)\n\u001b[1;32m      3\u001b[0m twitter_archive_clean.pet_class = twitter_archive_clean.pet_class.apply(\n\u001b[1;32m      4\u001b[0m     lambda x: np.nan if x is '' else x)\n\u001b[1;32m      5\u001b[0m twitter_archive_clean.drop(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twitter_archive_clean' is not defined"
     ]
    }
   ],
   "source": [
    "twitter_archive_clean['pet_class'] = twitter_archive_clean[[\n",
    "    'doggo', 'floofer', 'pupper', 'puppo']].fillna('').sum(axis=1)\n",
    "twitter_archive_clean.pet_class = twitter_archive_clean.pet_class.apply(\n",
    "    lambda x: np.nan if x is '' else x)\n",
    "twitter_archive_clean.drop(\n",
    "    columns=['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Denominador se mostra desnecessário sendo sempre 10 em `twitter_archive` na coluna `rating_denominator` - Colunas `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp`.\n",
    "- Remove as colunas `rating_denominator`, `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` e `retweeted_status_timestamp` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.drop(columns=['rating_denominator', 'in_reply_to_status_id', 'in_reply_to_user_id',\n",
    "                                    'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Numero de imagens na coluna `img_num` se mostra desnecessário em `image_predictions`.\n",
    "- Remove a coluna `img_num` utilizando `drop`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.drop(columns='img_num', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_pretictions_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define - Junção de df_tweets, image_predicitions e twitter_archive.\n",
    "- Gera um merge chamado `twitter_archive_master` com a junção das tabelas `twitter_archive` e `df_tweets`\n",
    "- Junta `twitter_archive_master` com a tabela faltante `image_predicions`\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# junta `twitter_archive_clean` com `df_tweets_clean`\n",
    "twitter_archive_master = twitter_archive_clean.merge(\n",
    "    df_tweets_clean, how='left', on=['tweet_id', 'text', 'expanded_urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junta `twitter_archive_master` com `image_predictions_clean`\n",
    "twitter_archive_master = twitter_archive_master.merge(\n",
    "    image_pretictions_clean, how='left', on=['tweet_id', 'jpg_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - `twitter_archive_master` table\n",
    "\n",
    "#### Define - Limpar urls que não levam a dog_rates\n",
    "- Seleciona urls que não contem `https://twitter.com/dog_rates` e remove as linhas utilizando os índices.\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_clean = twitter_archive_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove por tweets que não pertençam a https://twitter.com/dog_rates\n",
    "no_tweets_index = twitter_archive_master_clean[~twitter_archive_master_clean.expanded_urls.str.contains(\n",
    "    'https://twitter.com/dog_rates', regex=False)].index\n",
    "twitter_archive_master_clean.drop(no_tweets_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_master_clean[~twitter_archive_master_clean.expanded_urls.str.contains(\n",
    "    'https://twitter.com/dog_rates', regex=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_clean.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o dataframe\n",
    "df_tweets_archive = pd.read_csv(\n",
    "    'twitter_archive_master.csv', parse_dates=['timestamp'])\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.describe().to_csv('csv/tab1.csv')\n",
    "df_tweets_archive.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual a média das notas por classificação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive.rating_numerator.describe().to_csv('csv/tab2.csv')\n",
    "df_tweets_archive.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive[df_tweets_archive.rating_numerator <=\n",
    "                  15].rating_numerator.describe().to_csv('csv/tab3.csv')\n",
    "df_tweets_archive[df_tweets_archive.rating_numerator <=\n",
    "                  15].rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=df_tweets_archive[df_tweets_archive.rating_numerator <= 15].rating_numerator)\n",
    "ax.set_title('Boxplot das notas atribuídas aos animais')\n",
    "ax.set_ylabel('Notas')\n",
    "ax.set_xticks([])\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig1.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Neste gráfico podemos verificar depois de remover as notas discrepantes, ou seja superiores a 15, assim removendo outliers (valores que podiam chegar a 1776, sendo que a nota deveria ser até 10 visto que o denominador é 10 mas os usuários como brincadeira classificam os animais com notas a cima desse valor), e com média de 10.49 e desvio de 2.19. Observa-se que existe uma homogeniedade da variância no boxplot, visto que a diferença entre o terceiro quartil e a mediana assim como a diferença entre o primeiro quartil e a mediana parecem ser a mesmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relação entre contagem de retweets e tweets favoritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax = sns.scatterplot(x=\"retweet_count\", y=\"favorite_count\",\n",
    "                     hue='pet_class', data=df_tweets_archive)\n",
    "ax.set_title('Contagens de retweets por tweets favoritados por classificação')\n",
    "ax.set_xlabel('Contagem retweets')\n",
    "ax.set_ylabel('Contagem tweets favoritos')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig2.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Esse é um gráfico de dispersão, entre a contagem de retweets e a contagem de tweets favoritos para cada classificação. Observa-se que a medida que aumenta a contagem de retweets aumenta a contagem de tweets favoritos (o que pode ser devido a maior visibilidade do tweet) e a classe que possui a maior evidência é a classe pupper. Vale salientar que é possível observar que a classe doggo possui observações com maiores números de retweets, consequentemente, maior contagem de tweets favoritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"pet_class\", y=\"retweet_count\", data=df_tweets_archive)\n",
    "labels = df_tweets_archive.pet_class.unique()[1:]\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=labels)\n",
    "ax.set_title('Contagens de retweets por classificação')\n",
    "ax.set_xlabel('Classificação dos animais')\n",
    "ax.set_ylabel('Contagem de retweets')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig3.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Por este gráfico é possível verificar que realmente a classificação doggo é a que possui o tweet com maior número de retweets, porém também podemos ver que pupper tem um grande concentração de retweets até 20000. Cachorros que possuem duas classificações são poucos com relação aos demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"pet_class\", y=\"favorite_count\", data=df_tweets_archive)\n",
    "labels = df_tweets_archive.pet_class.unique()[1:]\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=labels)\n",
    "ax.set_title('Contagens de tweets favoritados por classificação')\n",
    "ax.set_xlabel('Classificação dos animais')\n",
    "ax.set_ylabel('Contagem de tweets favoritos')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig4.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_archive[['retweet_count', 'favorite_count']].corr().to_csv('csv/tab4.csv')\n",
    "df_tweets_archive[['retweet_count', 'favorite_count']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Ao comparar a correlação entre `retweet_count` e `favorite_count` pode-se notar que existe uma forte correlação positiva entre as variáveis, isto é a médida que a contagem de retweets aumenta significa o quão favorito aquele tweet é com os usuários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contagem de tweets por data da post e classificação do animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = df_tweets_archive.set_index('timestamp')\n",
    "graph = graph.groupby([pd.Grouper(freq='M'), 'pet_class']).count()\n",
    "graph = graph.reset_index(level=['timestamp', 'pet_class'])\n",
    "\n",
    "ax = sns.lineplot(x='timestamp', y='tweet_id', data=graph, hue='pet_class')\n",
    "ax.set_xticklabels(rotation=45, ha='right', labels=graph.timestamp.dt.date)\n",
    "ax.set_title('Contagem de tweets por data e classificação')\n",
    "ax.set_xlabel('Data')\n",
    "ax.set_ylabel('Contagem')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('imgs/fig5.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "Ao inicio é possível observar que a grande maioria dos tweets com classificação eram classificados unicamente como pupper, a medida que o tempo passa outras classificações são utilizadas e a contagem de tweets de cachorros denominados como pupper diminuiu. Observa-se que embora tenham ocorrido diferentes classificações, como doggo por exemplo, o número de tweets que possuem os animais denominados nessas classes diminuiu entre os anos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
